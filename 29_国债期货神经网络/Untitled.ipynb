{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.1200s). Check your callbacks.\n",
      "329/329 - 4s - loss: 1.2343 - val_loss: 0.5898\n",
      "Epoch 2/100\n",
      "329/329 - 3s - loss: 1.0410 - val_loss: 0.5376\n",
      "Epoch 3/100\n",
      "329/329 - 3s - loss: 0.9694 - val_loss: 0.5058\n",
      "Epoch 4/100\n",
      "329/329 - 4s - loss: 0.9244 - val_loss: 0.4961\n",
      "Epoch 5/100\n",
      "329/329 - 4s - loss: 0.8223 - val_loss: 0.4791\n",
      "Epoch 6/100\n",
      "329/329 - 4s - loss: 0.7926 - val_loss: 0.4542\n",
      "Epoch 7/100\n",
      "329/329 - 3s - loss: 0.7646 - val_loss: 0.4361\n",
      "Epoch 8/100\n",
      "329/329 - 3s - loss: 0.7662 - val_loss: 0.4090\n",
      "Epoch 9/100\n",
      "329/329 - 3s - loss: 0.7429 - val_loss: 0.4261\n",
      "Epoch 10/100\n",
      "329/329 - 3s - loss: 0.7276 - val_loss: 0.3841\n",
      "Epoch 11/100\n",
      "329/329 - 3s - loss: 0.7036 - val_loss: 0.3819\n",
      "Epoch 12/100\n",
      "329/329 - 3s - loss: 0.6844 - val_loss: 0.4004\n",
      "Epoch 13/100\n",
      "329/329 - 3s - loss: 0.6310 - val_loss: 0.3494\n",
      "Epoch 14/100\n",
      "329/329 - 4s - loss: 0.6263 - val_loss: 0.3571\n",
      "Epoch 15/100\n",
      "329/329 - 4s - loss: 0.6170 - val_loss: 0.3357\n",
      "Epoch 16/100\n",
      "329/329 - 3s - loss: 0.5701 - val_loss: 0.3094\n",
      "Epoch 17/100\n",
      "329/329 - 4s - loss: 0.5932 - val_loss: 0.3264\n",
      "Epoch 18/100\n",
      "329/329 - 3s - loss: 0.5733 - val_loss: 0.3327\n",
      "Epoch 19/100\n",
      "329/329 - 3s - loss: 0.5970 - val_loss: 0.3378\n",
      "Epoch 20/100\n",
      "329/329 - 3s - loss: 0.5808 - val_loss: 0.3276\n",
      "Epoch 21/100\n",
      "329/329 - 4s - loss: 0.5785 - val_loss: 0.3068\n",
      "Epoch 22/100\n",
      "329/329 - 4s - loss: 0.5694 - val_loss: 0.3136\n",
      "Epoch 23/100\n",
      "329/329 - 4s - loss: 0.5871 - val_loss: 0.2968\n",
      "Epoch 24/100\n",
      "329/329 - 3s - loss: 0.5668 - val_loss: 0.2940\n",
      "Epoch 25/100\n",
      "329/329 - 3s - loss: 0.5557 - val_loss: 0.2978\n",
      "Epoch 26/100\n",
      "329/329 - 3s - loss: 0.5538 - val_loss: 0.2996\n",
      "Epoch 27/100\n",
      "329/329 - 3s - loss: 0.5421 - val_loss: 0.2983\n",
      "Epoch 28/100\n",
      "329/329 - 3s - loss: 0.5213 - val_loss: 0.2770\n",
      "Epoch 29/100\n",
      "329/329 - 3s - loss: 0.5046 - val_loss: 0.2806\n",
      "Epoch 30/100\n",
      "329/329 - 3s - loss: 0.5024 - val_loss: 0.2717\n",
      "Epoch 31/100\n",
      "329/329 - 3s - loss: 0.4866 - val_loss: 0.2617\n",
      "Epoch 32/100\n",
      "329/329 - 3s - loss: 0.4782 - val_loss: 0.2680\n",
      "Epoch 33/100\n",
      "329/329 - 3s - loss: 0.4922 - val_loss: 0.2606\n",
      "Epoch 34/100\n",
      "329/329 - 3s - loss: 0.4944 - val_loss: 0.2711\n",
      "Epoch 35/100\n",
      "329/329 - 3s - loss: 0.4786 - val_loss: 0.2524\n",
      "Epoch 36/100\n",
      "329/329 - 3s - loss: 0.4863 - val_loss: 0.2518\n",
      "Epoch 37/100\n",
      "329/329 - 3s - loss: 0.4855 - val_loss: 0.2587\n",
      "Epoch 38/100\n",
      "329/329 - 3s - loss: 0.4992 - val_loss: 0.2626\n",
      "Epoch 39/100\n",
      "329/329 - 3s - loss: 0.4918 - val_loss: 0.2585\n",
      "Epoch 40/100\n",
      "329/329 - 3s - loss: 0.4591 - val_loss: 0.2406\n",
      "Epoch 41/100\n",
      "329/329 - 3s - loss: 0.4607 - val_loss: 0.2487\n",
      "Epoch 42/100\n",
      "329/329 - 3s - loss: 0.4596 - val_loss: 0.2432\n",
      "Epoch 43/100\n",
      "329/329 - 3s - loss: 0.4528 - val_loss: 0.2401\n",
      "Epoch 44/100\n",
      "329/329 - 3s - loss: 0.4437 - val_loss: 0.2312\n",
      "Epoch 45/100\n",
      "329/329 - 3s - loss: 0.4499 - val_loss: 0.2390\n",
      "Epoch 46/100\n",
      "329/329 - 3s - loss: 0.4513 - val_loss: 0.2311\n",
      "Epoch 47/100\n",
      "329/329 - 3s - loss: 0.4518 - val_loss: 0.2390\n",
      "Epoch 48/100\n",
      "329/329 - 3s - loss: 0.4601 - val_loss: 0.2434\n",
      "Epoch 49/100\n",
      "329/329 - 3s - loss: 0.4662 - val_loss: 0.2362\n",
      "Epoch 50/100\n",
      "329/329 - 3s - loss: 0.4776 - val_loss: 0.2320\n",
      "Epoch 51/100\n",
      "329/329 - 3s - loss: 0.4667 - val_loss: 0.2402\n",
      "Epoch 52/100\n",
      "329/329 - 3s - loss: 0.4617 - val_loss: 0.2291\n",
      "Epoch 53/100\n",
      "329/329 - 3s - loss: 0.4617 - val_loss: 0.2282\n",
      "Epoch 54/100\n",
      "329/329 - 3s - loss: 0.4723 - val_loss: 0.2314\n",
      "Epoch 55/100\n",
      "329/329 - 3s - loss: 0.4660 - val_loss: 0.2208\n",
      "Epoch 56/100\n",
      "329/329 - 3s - loss: 0.4588 - val_loss: 0.2339\n",
      "Epoch 57/100\n",
      "329/329 - 3s - loss: 0.4509 - val_loss: 0.2270\n",
      "Epoch 58/100\n",
      "329/329 - 3s - loss: 0.4412 - val_loss: 0.2212\n",
      "Epoch 59/100\n",
      "329/329 - 3s - loss: 0.4472 - val_loss: 0.2375\n",
      "Epoch 60/100\n",
      "329/329 - 3s - loss: 0.4467 - val_loss: 0.2253\n",
      "Epoch 61/100\n",
      "329/329 - 3s - loss: 0.4316 - val_loss: 0.2272\n",
      "Epoch 62/100\n",
      "329/329 - 3s - loss: 0.4364 - val_loss: 0.2205\n",
      "Epoch 63/100\n",
      "329/329 - 3s - loss: 0.4383 - val_loss: 0.2349\n",
      "Epoch 64/100\n",
      "329/329 - 3s - loss: 0.4430 - val_loss: 0.2413\n",
      "Epoch 65/100\n",
      "329/329 - 3s - loss: 0.4633 - val_loss: 0.2310\n",
      "Epoch 66/100\n",
      "329/329 - 3s - loss: 0.4477 - val_loss: 0.2331\n",
      "Epoch 67/100\n",
      "329/329 - 3s - loss: 0.4444 - val_loss: 0.2348\n",
      "Epoch 68/100\n",
      "329/329 - 3s - loss: 0.4423 - val_loss: 0.2310\n",
      "Epoch 69/100\n",
      "329/329 - 3s - loss: 0.4254 - val_loss: 0.2143\n",
      "Epoch 70/100\n",
      "329/329 - 3s - loss: 0.4200 - val_loss: 0.2244\n",
      "Epoch 71/100\n",
      "329/329 - 3s - loss: 0.4050 - val_loss: 0.2152\n",
      "Epoch 72/100\n",
      "329/329 - 3s - loss: 0.3972 - val_loss: 0.2159\n",
      "Epoch 73/100\n",
      "329/329 - 3s - loss: 0.4055 - val_loss: 0.2215\n",
      "Epoch 74/100\n",
      "329/329 - 3s - loss: 0.3998 - val_loss: 0.2076\n",
      "Epoch 75/100\n",
      "329/329 - 3s - loss: 0.3908 - val_loss: 0.2046\n",
      "Epoch 76/100\n",
      "329/329 - 3s - loss: 0.3909 - val_loss: 0.2056\n",
      "Epoch 77/100\n",
      "329/329 - 3s - loss: 0.3900 - val_loss: 0.2045\n",
      "Epoch 78/100\n",
      "329/329 - 3s - loss: 0.3875 - val_loss: 0.1940\n",
      "Epoch 79/100\n",
      "329/329 - 3s - loss: 0.3958 - val_loss: 0.2010\n",
      "Epoch 80/100\n",
      "329/329 - 3s - loss: 0.4032 - val_loss: 0.1988\n",
      "Epoch 81/100\n",
      "329/329 - 3s - loss: 0.3969 - val_loss: 0.2024\n",
      "Epoch 82/100\n",
      "329/329 - 3s - loss: 0.4134 - val_loss: 0.2046\n",
      "Epoch 83/100\n",
      "329/329 - 3s - loss: 0.4075 - val_loss: 0.2094\n",
      "Epoch 84/100\n",
      "329/329 - 3s - loss: 0.4082 - val_loss: 0.2035\n",
      "Epoch 85/100\n",
      "329/329 - 3s - loss: 0.3970 - val_loss: 0.1992\n",
      "Epoch 86/100\n",
      "329/329 - 3s - loss: 0.3726 - val_loss: 0.1938\n",
      "Epoch 87/100\n",
      "329/329 - 3s - loss: 0.3655 - val_loss: 0.1958\n",
      "Epoch 88/100\n",
      "329/329 - 3s - loss: 0.3713 - val_loss: 0.1928\n",
      "Epoch 89/100\n",
      "329/329 - 3s - loss: 0.3660 - val_loss: 0.1923\n",
      "Epoch 90/100\n",
      "329/329 - 3s - loss: 0.3721 - val_loss: 0.1956\n",
      "Epoch 91/100\n",
      "329/329 - 3s - loss: 0.3672 - val_loss: 0.1968\n",
      "Epoch 92/100\n",
      "329/329 - 3s - loss: 0.3592 - val_loss: 0.1918\n",
      "Epoch 93/100\n",
      "329/329 - 3s - loss: 0.3582 - val_loss: 0.1884\n",
      "Epoch 94/100\n",
      "329/329 - 3s - loss: 0.3552 - val_loss: 0.1840\n",
      "Epoch 95/100\n",
      "329/329 - 3s - loss: 0.3536 - val_loss: 0.1872\n",
      "Epoch 96/100\n",
      "329/329 - 3s - loss: 0.3616 - val_loss: 0.1903\n",
      "Epoch 97/100\n",
      "329/329 - 3s - loss: 0.3622 - val_loss: 0.1873\n",
      "Epoch 98/100\n",
      "329/329 - 3s - loss: 0.3563 - val_loss: 0.1876\n",
      "Epoch 99/100\n",
      "329/329 - 3s - loss: 0.3689 - val_loss: 0.1866\n",
      "Epoch 100/100\n",
      "329/329 - 3s - loss: 0.3608 - val_loss: 0.1844\n",
      "test set\n",
      "\n",
      "The test loss is 0.180592\n",
      "79/79 [==============================] - 0s 3ms/step\n",
      "The accuracy of the model is 0.943300\n"
     ]
    }
   ],
   "source": [
    "# =================== Test 1    Hello Keras for mnist==============================================================================\n",
    "# 这是一个简单的全连接神经网络的例子。\n",
    "from keras.models import Sequential  # 采用贯序模型\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "tBatchSize = 128\n",
    "'''第一步：选择模型'''\n",
    "model = Sequential()  # 采用贯序模型\n",
    "\n",
    "'''第二步：构建网络层'''\n",
    "'''构建网络只是构建了一个网络结构，并定义网络的参数，此时还没有输入的数据集'''\n",
    "# 构建的第一个层作为输入层\n",
    "# Dense 这是第一个隐藏层，并附带定义了输入层，该隐含层有500个神经元。输入则是 784个节点\n",
    "model.add(Dense(500, input_shape=(784,)))  # 输入层，28*28=784 输入层将二维矩阵换成了一维向量输入\n",
    "model.add(Activation('tanh'))  # 激活函数是tanh 为双曲正切  tanh(x) = sinh(x)/cosh(x) = (e^x - e^(-x))/(e^x + e^(-x))\n",
    "model.add(Dropout(0.5))  # 采用50%的dropout  随机取一半进行训练\n",
    "\n",
    "# 构建的第2个层作为隐藏层2， （如果加上输入层，实际上是第三层）\n",
    "model.add(Dense(500))  # 隐藏层节点500个\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(500))  # 隐藏层3，节点500个\n",
    "model.add(Activation('tanh'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# 构建的第3个层作为输出层\n",
    "model.add(Dense(10))  # 输出结果是10个类别，所以维度是10\n",
    "# softmax介绍可以参考https://blog.csdn.net/haolexiao/article/details/72757796\n",
    "model.add(Activation('softmax'))  # 最后一层用softmax作为激活函数\n",
    "\n",
    "'''第三步：网络优化和编译'''\n",
    "#   lr：大于0的浮点数，学习率\n",
    "#   momentum：大于0的浮点数，动量参数\n",
    "#   decay：大于0的浮点数，每次更新后的学习率衰减值\n",
    "#   nesterov：布尔值，确定是否使用Nesterov动量\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)  # 优化函数，设定学习率（lr）等参数\n",
    "\n",
    "# 只有通过了编译，model才真正的建立起来，这时候才能够被使用\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=sgd, class_mode='categorical') # 使用交叉熵作为loss函数 这是原例子，但是执行出错\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)  # 使用交叉熵作为loss函数    # 去掉 class_mode 即可。可能是版本不同导致的？？？\n",
    "\n",
    "'''\n",
    "   第四步：训练\n",
    "'''\n",
    "\n",
    "# 数据集获取 mnist 数据集的介绍可以参考 https://blog.csdn.net/simple_the_best/article/details/75267863\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()  # 使用Keras自带的mnist工具读取数据（第一次需要联网）\n",
    "\n",
    "# 由于mist的输入数据维度是(num, 28, 28)，这里需要把后面的维度直接拼起来变成784维\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "\n",
    "# 这个能生成一个OneHot的10维向量，作为Y_train的一行，这样Y_train就有60000行OneHot作为输出\n",
    "Y_train = (np.arange(10) == y_train[:, None]).astype(int)  # 整理输出\n",
    "Y_test = (np.arange(10) == y_test[:, None]).astype(int)  # np.arange(5) = array([0,1,2,3,4])\n",
    "\n",
    "'''\n",
    "   .fit的一些参数\n",
    "   batch_size：对总的样本数进行分组，每组包含的样本数量\n",
    "   epochs ：训练次数\n",
    "   shuffle：是否把数据随机打乱之后再进行训练\n",
    "   validation_split：拿出百分之多少用来做交叉验证\n",
    "   verbose：屏显模式 0：不输出  1：输出进度  2：输出每次的训练结果\n",
    "'''\n",
    "tbCallBack = TensorBoard(log_dir=\"./log\", histogram_freq=1,write_grads=True)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=tBatchSize, \n",
    "          epochs=100, shuffle=True, \n",
    "          verbose=2, validation_split=0.3,\n",
    "          callbacks=[tbCallBack])\n",
    "\n",
    "\n",
    "# model.evaluate(X_test, Y_test, batch_size=200, verbose=0)\n",
    "\n",
    "\n",
    "'''第五步：输出'''\n",
    "print(\"test set\")\n",
    "# 误差评价 ：按batch计算在batch用到的输入数据上模型的误差\n",
    "scores = model.evaluate(X_test, Y_test, batch_size=tBatchSize, verbose=0)\n",
    "print(\"\")\n",
    "print(\"The test loss is %f\" % scores)\n",
    "\n",
    "# 根据模型获取预测结果  为了节约计算内存，也是分组（batch）load到内存中的，\n",
    "result = model.predict(X_test, batch_size=tBatchSize, verbose=1)\n",
    "\n",
    "# 找到每行最大的序号\n",
    "result_max = np.argmax(result, axis=1)  # axis=1表示按行 取最大值   如果axis=0表示按列 取最大值 axis=None表示全部\n",
    "test_max = np.argmax(Y_test, axis=1)  # 这是结果的真实序号\n",
    "\n",
    "result_bool = np.equal(result_max, test_max)  # 预测结果和真实结果一致的为真（按元素比较）\n",
    "true_num = np.sum(result_bool)  # 正确结果的数量\n",
    "print(\"The accuracy of the model is %f\" % (true_num / len(result_bool)))  # 验证结果的准确率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
